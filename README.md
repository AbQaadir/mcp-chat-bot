# AI-Powered Resume Processing & Chat System

A comprehensive full-stack application that combines resume processing, semantic search, and AI-powered chat capabilities. Built with modern microservices architecture using FastAPI, Next.js, and advanced AI technologies.

## ğŸŒŸ Overview

This system provides an intelligent resume processing platform where users can:
- Upload PDF resumes for automated processing and analysis
- Chat with an AI assistant about resume content using natural language
- Perform semantic search across uploaded resumes
- Leverage advanced language models for resume insights and recommendations

## ğŸ—ï¸ Architecture

The system follows a microservices architecture with the following components:

```mermaid
graph TB
    %% User Layer
    User[ğŸ‘¤ User] --> Frontend
    
    %% Frontend Layer
    Frontend[ğŸŒ Next.js Frontend<br/>Port 3000] --> API
    
    %% API Layer
    API[ğŸ–¥ï¸ FastAPI Server<br/>Port 8000] --> FastMCP
    API --> Celery
    API --> Redis
    
    %% MCP Layer
    FastMCP[ğŸ”Œ FastMCP Server<br/>Port 8005] --> DB
    
    %% Worker Layer
    Celery[âš™ï¸ Celery Worker<br/>Background Tasks] --> Redis
    Celery --> DB
    
    %% Storage Layer
    Redis[ğŸ“¦ Redis<br/>Port 6379<br/>Message Broker]
    DB[(ğŸ—„ï¸ PostgreSQL + pgvector<br/>Port 5432<br/>Vector Database)]
    
    %% Monitoring Layer
    Flower[ğŸŒ¸ Flower<br/>Port 5555<br/>Task Monitor] --> Redis
    PgAdmin[ğŸ”§ pgAdmin<br/>Port 5050<br/>DB Admin] --> DB
    
    %% Shared Storage
    API -.-> Uploads[ğŸ“ Shared Upload Volume]
    Celery -.-> Uploads
    Flower -.-> Uploads
    
    %% Styling
    classDef frontend fill:#e1f5fe
    classDef backend fill:#f3e5f5
    classDef storage fill:#e8f5e8
    classDef monitoring fill:#fff3e0
    
    class Frontend frontend
    class API,FastMCP backend
    class Redis,DB,Uploads storage
    class Flower,PgAdmin monitoring
```

## ğŸš€ Key Features

### Resume Processing
- **Multi-file PDF upload** with drag-and-drop interface
- **Asynchronous processing** using Celery for scalability
- **Intelligent text chunking** for optimal embedding generation
- **Vector storage** in PostgreSQL with pgvector extension
- **Semantic search** capabilities using Google Generative AI

### AI Chat Interface
- **Streaming chat responses** for real-time interaction
- **Context-aware conversations** about uploaded resumes
- **Model Context Protocol (MCP)** integration for advanced AI capabilities
- **Markdown support** for rich text rendering
- **Message history** persistence

### System Management
- **Docker containerization** for easy deployment
- **Health checks** for service monitoring
- **Flower dashboard** for Celery task monitoring
- **pgAdmin** for database administration
- **CORS support** for frontend-backend communication

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Celery** - Asynchronous task queue
- **Redis** - Message broker and caching
- **PostgreSQL** - Primary database
- **pgvector** - Vector similarity search
- **LangChain** - AI/ML framework
- **Google Generative AI** - Embeddings and language models

### Frontend
- **Next.js 15** - React framework with Turbopack
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first styling
- **React Markdown** - Rich text rendering

### DevOps & Infrastructure
- **Docker** & **Docker Compose** - Containerization
- **Python 3.11+** - Backend runtime
- **Node.js 20** - Frontend runtime
- **UV** - Fast Python package installer

## ğŸ“¦ Quick Start

### Prerequisites
- Docker and Docker Compose
- Google API key for Generative AI
- 8GB+ RAM recommended
- 10GB+ free disk space

### 1. Clone the Repository
```bash
git clone <repository-url>
cd assignment
```

### 2. Environment Configuration

#### FastAPI Server Configuration
```bash
cp fastapi-server/.env.example fastapi-server/.env
```

Edit `fastapi-server/.env`:
```env
# Database Configuration
PG_CONNECTION_STRING=postgresql://postgres:postgres@db:5432/resumedb

# Redis/Celery Configuration  
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# Google AI Configuration
GOOGLE_API_KEY=your_google_api_key_here
EMBEDDING_MODEL=models/embedding-001

# System Configuration
UPLOAD_DIR=/tmp/resume_uploads
MODEL_NAME=gemini-2.0-flash-exp
MODEL_PROVIDER=google_genai
```

#### FastMCP Server Configuration
```bash
cp fastmcp-server/.env.example fastmcp-server/.env
```

Edit `fastmcp-server/.env`:
```env
PG_CONNECTION_STRING=postgresql://postgres:postgres@db:5432/resumedb
GOOGLE_API_KEY=your_google_api_key_here
EMBEDDING_MODEL=models/embedding-001
```

### 3. Launch the System
```bash
# Start all services
docker-compose up -d

# View startup logs
docker-compose logs -f

# Check service status
docker-compose ps
```

### 4. Access the Application

Once all services are running, access:

| Service | URL | Purpose |
|---------|-----|---------|
| **Main Application** | http://localhost:3000 | Frontend chat interface |
| **API Documentation** | http://localhost:8000/docs | Swagger UI for API |
| **Database Admin** | http://localhost:5050 | pgAdmin interface |
| **Task Monitor** | http://localhost:5555 | Flower Celery dashboard |
| **FastMCP Server** | http://localhost:8005 | MCP protocol endpoint |

#### Default Credentials
- **pgAdmin**: admin@admin.com / admin
- **PostgreSQL**: postgres / postgres


## ğŸ”§ Configuration & Customization

### Environment Variables

#### Core System
| Variable | Description | Default |
|----------|-------------|---------|
| `PG_CONNECTION_STRING` | PostgreSQL connection URL | `postgresql://postgres:postgres@db:5432/resumedb` |
| `CELERY_BROKER_URL` | Redis broker for Celery | `redis://redis:6379/0` |
| `CELERY_RESULT_BACKEND` | Redis backend for Celery | `redis://redis:6379/0` |
| `UPLOAD_DIR` | Directory for file uploads | `/tmp/resume_uploads` |

#### AI Configuration
| Variable | Description | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` | Google AI API key | **Required** |
| `EMBEDDING_MODEL` | Embedding model name | `models/embedding-001` |
| `MODEL_NAME` | Chat model name | `gemini-2.0-flash-exp` |
| `MODEL_PROVIDER` | Model provider | `google_genai` |

#### Frontend
| Variable | Description | Default |
|----------|-------------|---------|
| `NEXT_PUBLIC_API_URL` | Backend API URL | `http://localhost:8000` |



#### Database Performance
```bash
# Access PostgreSQL for optimization
docker-compose exec db psql -U postgres -d resumedb

# Create additional indexes for performance
CREATE INDEX CONCURRENTLY ON documents USING ivfflat (embedding vector_cosine_ops);
```

## ğŸ“ Project Structure

### ğŸ  Root Directory
```
assignment/
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ fastapi-server/
â”œâ”€â”€ fastmcp-server/
â””â”€â”€ next-frontend/
```

### ğŸ–¥ï¸ FastAPI Server Structure
```
fastapi-server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ worker.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ upload.py
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ request.py
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ service.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ mcp_agent.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ __pycache__/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```
```
fastapi-server/
â”œâ”€â”€ ğŸ“ app/                         # Main application package
â”‚   â”œâ”€â”€ ğŸ __init__.py             # Package initialization
â”‚   â”œâ”€â”€ ğŸ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ ğŸ core.py                 # Core FastAPI app configuration
â”‚   â”œâ”€â”€ âš™ï¸ worker.py               # Celery task definitions & worker
â”‚   â”‚
â”‚   â”œâ”€â”€ ï¿½ config/                  # Configuration management
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py         # Package initialization
â”‚   â”‚   â””â”€â”€ âš™ï¸ settings.py         # Environment variables & settings
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ routes/                  # API endpoint definitions
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py         # Package initialization
â”‚   â”‚   â”œâ”€â”€ ğŸ“¤ upload.py           # File upload endpoints & logic
â”‚   â”‚   â””â”€â”€ ğŸ’¬ chat.py             # Chat API endpoints & streaming
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ schemas/                 # Pydantic models & validation
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py         # Package initialization
â”‚   â”‚   â”œâ”€â”€ ğŸ“ request.py          # API request/response models
â”‚   â”‚   â””â”€â”€ ğŸ’¬ chat.py             # Chat-specific data schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ ingestion/               # Document processing pipeline
â”‚   â”‚   â”œâ”€â”€ ï¿½ __init__.py         # Package initialization
â”‚   â”‚   â””â”€â”€ ğŸ”„ service.py          # PDF processing & vectorization
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ agents/                  # AI agent management
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py         # Package initialization
â”‚   â”‚   â””â”€â”€ ğŸ¤– mcp_agent.py        # MCP agent configuration & logic
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                   # Utility functions & helpers
â”‚       â”œâ”€â”€ ğŸ __init__.py         # Package initialization
â”‚       â””â”€â”€ ğŸ› ï¸ helpers.py          # File handling & common utilities
â”‚
â”œâ”€â”€ ğŸ“ __pycache__/                 # Python bytecode cache
â”œâ”€â”€ ğŸ³ Dockerfile                   # Container configuration
â”œâ”€â”€ ğŸ“¦ requirements.txt             # Python dependencies (pip)
â”œâ”€â”€ âš™ï¸ pyproject.toml              # Project metadata & dependencies (UV)
â”œâ”€â”€ ğŸ”’ uv.lock                     # UV dependency lock file
â””â”€â”€ ğŸ“„ README.md                   # Service-specific documentation
```

### ğŸ”Œ FastMCP Server Structure
```
fastmcp-server/
â”œâ”€â”€ server.py
â”œâ”€â”€ config.py
â”œâ”€â”€ __pycache__/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```

### ğŸŒ Next.js Frontend Structure
```
next-frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”œâ”€â”€ page.tsx
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ChatInterface.tsx
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ api.ts
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ file.svg
â”‚   â”œâ”€â”€ globe.svg
â”‚   â”œâ”€â”€ next.svg
â”‚   â”œâ”€â”€ vercel.svg
â”‚   â””â”€â”€ window.svg
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â”œâ”€â”€ next.config.ts
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ next-env.d.ts
â”œâ”€â”€ eslint.config.mjs
â”œâ”€â”€ postcss.config.mjs
â””â”€â”€ README.md
```

## ğŸš€ Deployment Options

### Production Deployment

#### Kubernetes
```yaml
# Example deployment configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fastapi-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: fastapi-server
  template:
    metadata:
      labels:
        app: fastapi-server
    spec:
      containers:
      - name: fastapi
        image: resume-app/fastapi-server:latest
        ports:
        - containerPort: 8000
```

## ğŸ“š Additional Resources

### Documentation
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Next.js Documentation](https://nextjs.org/docs)
- [LangChain Documentation](https://docs.langchain.com/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Celery Documentation](https://docs.celeryproject.org/)

### API References
- [Google Generative AI API](https://ai.google.dev/docs)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Redis Documentation](https://redis.io/documentation)

### Community
- [FastAPI Community](https://github.com/tiangolo/fastapi/discussions)
- [LangChain Community](https://github.com/langchain-ai/langchain/discussions)
- [Next.js Community](https://github.com/vercel/next.js/discussions)
